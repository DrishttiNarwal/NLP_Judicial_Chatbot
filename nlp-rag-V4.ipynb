{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9921368,"sourceType":"datasetVersion","datasetId":6097537}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:16:52.668747Z","iopub.execute_input":"2024-11-16T18:16:52.669156Z","iopub.status.idle":"2024-11-16T18:16:52.689819Z","shell.execute_reply.started":"2024-11-16T18:16:52.669118Z","shell.execute_reply":"2024-11-16T18:16:52.688903Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-rag-data/data.csv\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!pip install accelerate -U -qq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:16:52.691784Z","iopub.execute_input":"2024-11-16T18:16:52.692134Z","iopub.status.idle":"2024-11-16T18:17:04.862425Z","shell.execute_reply.started":"2024-11-16T18:16:52.692097Z","shell.execute_reply":"2024-11-16T18:17:04.861304Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"!pip install bitsandbytes -qq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:17:04.863897Z","iopub.execute_input":"2024-11-16T18:17:04.864263Z","iopub.status.idle":"2024-11-16T18:17:16.923408Z","shell.execute_reply.started":"2024-11-16T18:17:04.864227Z","shell.execute_reply":"2024-11-16T18:17:16.922115Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"!pip install chromadb -qq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:17:16.926401Z","iopub.execute_input":"2024-11-16T18:17:16.926755Z","iopub.status.idle":"2024-11-16T18:17:29.922341Z","shell.execute_reply.started":"2024-11-16T18:17:16.926719Z","shell.execute_reply":"2024-11-16T18:17:29.921225Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"!pip install langchain llama-index llama_hub -qq/content/drive/MyDrive/Sem 5/DL_FINAL_PROJ/data.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:17:29.924026Z","iopub.execute_input":"2024-11-16T18:17:29.924442Z","iopub.status.idle":"2024-11-16T18:17:31.453930Z","shell.execute_reply.started":"2024-11-16T18:17:29.924392Z","shell.execute_reply":"2024-11-16T18:17:31.452946Z"}},"outputs":[{"name":"stdout","text":"\nUsage:   \n  pip install [options] <requirement specifier> [package-index-options] ...\n  pip install [options] -r <requirements file> [package-index-options] ...\n  pip install [options] [-e] <vcs project url> ...\n  pip install [options] [-e] <local project path> ...\n  pip install [options] <archive url/path> ...\n\nno such option: -/\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!pip install sentence-transformers -qq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:17:31.455613Z","iopub.execute_input":"2024-11-16T18:17:31.456027Z","iopub.status.idle":"2024-11-16T18:17:43.432285Z","shell.execute_reply.started":"2024-11-16T18:17:31.455990Z","shell.execute_reply":"2024-11-16T18:17:43.430949Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"!pip install langchain-community -qq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:17:43.433987Z","iopub.execute_input":"2024-11-16T18:17:43.434345Z","iopub.status.idle":"2024-11-16T18:17:55.685731Z","shell.execute_reply.started":"2024-11-16T18:17:43.434310Z","shell.execute_reply":"2024-11-16T18:17:55.684623Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:17:55.687445Z","iopub.execute_input":"2024-11-16T18:17:55.687847Z","iopub.status.idle":"2024-11-16T18:18:07.776353Z","shell.execute_reply.started":"2024-11-16T18:17:55.687808Z","shell.execute_reply":"2024-11-16T18:18:07.775359Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain.chains.summarize import load_summarize_chain\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain import LLMChain\nfrom langchain.prompts.prompt import PromptTemplate\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nimport torch\nfrom transformers import BitsAndBytesConfig\nfrom langchain.document_transformers import LongContextReorder\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.schema.output_parser import StrOutputParser\nimport textwrap\nfrom langchain.schema import Document","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:07.777871Z","iopub.execute_input":"2024-11-16T18:18:07.778250Z","iopub.status.idle":"2024-11-16T18:18:07.786487Z","shell.execute_reply.started":"2024-11-16T18:18:07.778212Z","shell.execute_reply":"2024-11-16T18:18:07.785641Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def generate_answer(query):\n    # Only load and initialize models if they aren't already initialized\n    if 'tokenizer' not in globals():\n        global tokenizer, model, pipe, llm, vectorsdb, context_prompt\n\n        # Set model name and quantization config\n        name = \"NousResearch/Llama-2-7b-chat-hf\"\n        quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n                                                 bnb_4bit_quant_type=\"nf4\",\n                                                 bnb_4bit_use_double_quant=True,\n                                                 bnb_4bit_compute_dtype=torch.bfloat16)\n\n        # Load tokenizer and model\n        tokenizer = AutoTokenizer.from_pretrained(name, cache_dir=\"./model/\")\n        model = AutoModelForCausalLM.from_pretrained(name, cache_dir=\"./model/\",\n                                                     device_map=\"auto\",\n                                                     torch_dtype=torch.float16,\n                                                     quantization_config=quantization_config)\n\n        # Setup the text generation pipeline\n        pipe = pipeline(\"text-generation\",\n                        model=model,\n                        tokenizer=tokenizer,\n                        max_new_tokens=512,\n                        temperature=0.4,\n                        top_p=0.95,\n                        repetition_penalty=1.15)\n        llm = HuggingFacePipeline(pipeline=pipe)\n\n        # Define the context-based question prompt\n        context_prompt = ChatPromptTemplate.from_messages([\n            ('system', \"Answer the question using only the context\\n\\nQuestion: {question}\\n\\nContext: {context}\"),\n            ('user', \"{question}\")\n        ])\n\n        # Load and process CSV data\n        csv_path = \"/kaggle/input/nlp-rag-data/data.csv\"\n        df = pd.read_csv(csv_path)\n\n        # Combine relevant text fields (adjust based on dataset structure)\n        text_data = df.apply(lambda row: ' '.join(map(str, row.values)), axis=1).tolist()\n\n        # Wrap each text string in a Document object\n        documents = [Document(page_content=text) for text in text_data]\n\n        # Split data into chunks for retrieval\n        text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n        chunks = text_splitter.split_documents(documents)\n\n        # Create embeddings and vector store\n        embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n        embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n        vectorsdb = Chroma.from_documents(chunks, embeddings, persist_directory=\"db\")\n\n    # Retrieve context from vector store\n    context = vectorsdb.as_retriever().get_relevant_documents(query)\n\n    # Format the question and context for the prompt\n    question_input = {'context': context, 'question': query}\n    response = context_prompt.format(**question_input)\n\n    # Invoke the model and get the result\n    result = llm(response)\n\n    # Ensure we capture only the answer text starting from the last \"System:\" tag\n    if \"System:\" in result:\n        answer_start = result.rfind(\"System:\") + len(\"System:\")\n        answer = result[answer_start:].strip()\n\n        # Remove any additional tags like \"Human:\" after the answer\n        answer = answer.split(\"Human:\")[0].strip()\n\n        # Remove \"Context:\" if it still appears in the answer\n        if \"Context:\" in answer:\n            answer = answer.split(\"Context:\")[-1].strip()\n\n        # Remove introductory phrases\n        if answer.startswith(\"Based on the provided context,\"):\n            answer = answer[len(\"Based on the provided context,\"):].strip()\n\n        # Final check: filter out any remaining document or metadata content\n        if \"Document(\" in answer:\n            answer = answer.split(\"Document(\")[0].strip()\n\n        return answer  # Return only the cleaned answer text\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:07.790235Z","iopub.execute_input":"2024-11-16T18:18:07.790543Z","iopub.status.idle":"2024-11-16T18:18:07.806645Z","shell.execute_reply.started":"2024-11-16T18:18:07.790512Z","shell.execute_reply":"2024-11-16T18:18:07.805844Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Example query\nquery = \"What is the key insight from the DOJ data?\"\nresult = generate_answer(query)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:07.807763Z","iopub.execute_input":"2024-11-16T18:18:07.808184Z","iopub.status.idle":"2024-11-16T18:18:09.602784Z","shell.execute_reply.started":"2024-11-16T18:18:07.808147Z","shell.execute_reply":"2024-11-16T18:18:09.601800Z"}},"outputs":[{"name":"stdout","text":"[\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Example query\nquery = \"What is the mission or vision of the Department of Justice\"\nresult = generate_answer(query)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:09.604095Z","iopub.execute_input":"2024-11-16T18:18:09.604501Z","iopub.status.idle":"2024-11-16T18:18:14.135003Z","shell.execute_reply.started":"2024-11-16T18:18:09.604457Z","shell.execute_reply":"2024-11-16T18:18:14.134064Z"}},"outputs":[{"name":"stdout","text":"The mission or vision of the Department of Justice is facilitating administration of justice that is accessible, affordable, and efficient for all citizens.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# Example query\nquery = \"What does the Department of Justice do to support justice administration?\"\nresult = generate_answer(query)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:14.136119Z","iopub.execute_input":"2024-11-16T18:18:14.136417Z","iopub.status.idle":"2024-11-16T18:18:19.480040Z","shell.execute_reply.started":"2024-11-16T18:18:14.136379Z","shell.execute_reply":"2024-11-16T18:18:19.478800Z"}},"outputs":[{"name":"stdout","text":"the Department of Justice supports justice administration by facilitating the administration of justice that ensures easy access and timely delivery of justice to all citizens.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Example query/content/drive/MyDrive/Sem 5/DL_FINAL_PROJ/data.csv\nquery = \"What are the different sections or topics covered on the DOJ website?\"\nresult = generate_answer(query)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:19.481127Z","iopub.execute_input":"2024-11-16T18:18:19.481438Z","iopub.status.idle":"2024-11-16T18:18:27.107414Z","shell.execute_reply.started":"2024-11-16T18:18:19.481405Z","shell.execute_reply":"2024-11-16T18:18:27.106517Z"}},"outputs":[{"name":"stdout","text":"the different sections or topics covered on the DOJ website are:\n\n* Press releases\n* Guidelines for submission\n* Digital library\n* Release of state booklets highlighting dedicated state schemes, activities of DoJ, and beneficiaries\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# Example query\nquery = \"What resources or documents are available in the DOJ’s digital library?\"\nresult = generate_answer(query)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:27.108646Z","iopub.execute_input":"2024-11-16T18:18:27.109009Z","iopub.status.idle":"2024-11-16T18:18:34.415422Z","shell.execute_reply.started":"2024-11-16T18:18:27.108959Z","shell.execute_reply":"2024-11-16T18:18:34.414343Z"}},"outputs":[{"name":"stdout","text":"[\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Example query\nquery = \"How does the DOJ support justice administration at the state level?\"\nresult = generate_answer(query)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:34.416905Z","iopub.execute_input":"2024-11-16T18:18:34.417341Z","iopub.status.idle":"2024-11-16T18:18:41.941587Z","shell.execute_reply.started":"2024-11-16T18:18:34.417302Z","shell.execute_reply":"2024-11-16T18:18:41.940530Z"}},"outputs":[{"name":"stdout","text":"The Department of Justice (DOJ) supports justice administration at the state level through various means, including providing funding and resources to state and local law enforcement agencies, offering training and technical assistance programs, and collaborating with state and local officials on criminal justice issues.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Example query\nquery = \"What are the recent updates on the guidelines provided by the DOJ?\"\nresult = generate_answer(query)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:41.942876Z","iopub.execute_input":"2024-11-16T18:18:41.943259Z","iopub.status.idle":"2024-11-16T18:18:56.419887Z","shell.execute_reply.started":"2024-11-16T18:18:41.943224Z","shell.execute_reply":"2024-11-16T18:18:56.418840Z"}},"outputs":[{"name":"stdout","text":"[\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Example query\nquery = \"How does the DOJ support justice administration at the state level?\"\nresult = generate_answer(query)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:56.421022Z","iopub.execute_input":"2024-11-16T18:18:56.421305Z","iopub.status.idle":"2024-11-16T18:18:58.131228Z","shell.execute_reply.started":"2024-11-16T18:18:56.421274Z","shell.execute_reply":"2024-11-16T18:18:58.130219Z"}},"outputs":[{"name":"stdout","text":"[\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"pip install nltk\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:18:58.132650Z","iopub.execute_input":"2024-11-16T18:18:58.133100Z","iopub.status.idle":"2024-11-16T18:19:10.016677Z","shell.execute_reply.started":"2024-11-16T18:18:58.133058Z","shell.execute_reply":"2024-11-16T18:19:10.015478Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n\n# Define reference answers (based on your dataset)\nreference_answers = [\n    [\"The Department of Justice (DOJ) supports justice administration at the state level through various means, including providing funding and resources to state and local law enforcement agencies, offering training and technical assistance programs, and collaborating with state officials on criminal justice issues.\"],\n    [\"the Department of Justice supports justice administration by facilitating the administration of justice through various means such as appointing, resigning, and removing officials, enforcing contracts, and providing a nodal point for related activities.\"],\n    [\"The key insight from the DOJ data is that the Department of Justice (DOJ) has a website with various pages containing information on different topics, including press releases, history, Guidelines for submission, state booklets highlighting dedicated state schemes, and about the department.\"],\n    [\"\"\"the following resources or documents are available in the DOJ’s digital library:\n* Press releases\n* State booklets highlighting dedicated state schemes, activities of DoJ, and beneficiaries\n* Guidelines for submission\n* Digital library\n\"\"\"],\n\n]\n\n# Queries\nqueries = [\"How does the DOJ support justice administration at the state level?\",\n           \"What does the Department of Justice do to support justice administration?\",\n           \"What is the key insight from the DOJ data?\",\n           \"What resources or documents are available in the DOJ’s digital library?\"\n]\n\n# Function to generate answers using the pre-defined `generate_answer` function\ngenerated_answers = [generate_answer(query) for query in queries]\n\n# Tokenize the reference and generated answers\nreferences = [[[token for token in ref.split()] for ref in refs] for refs in reference_answers]\ncandidates = [gen.split() for gen in generated_answers]  # Tokenize generated answers\n\n# Calculate the corpus-level BLEU score\nsmooth = SmoothingFunction().method4\nbleu_score = corpus_bleu(references, candidates, smoothing_function=smooth)\n\n# Display the BLEU score\nprint(f\"Generalized BLEU Score: {bleu_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T18:21:14.624519Z","iopub.execute_input":"2024-11-16T18:21:14.624963Z","iopub.status.idle":"2024-11-16T18:21:44.728285Z","shell.execute_reply.started":"2024-11-16T18:21:14.624906Z","shell.execute_reply":"2024-11-16T18:21:44.727252Z"}},"outputs":[{"name":"stdout","text":"Generalized BLEU Score: 0.6571\n","output_type":"stream"}],"execution_count":45}]}